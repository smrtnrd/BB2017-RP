\relax 
\abx@aux@sortscheme{none}
\@writefile{toc}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\@writefile{lof}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\@writefile{lot}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\select@language{english}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\select@language{english}}
\abx@aux@cite{Ting2017}
\abx@aux@cite{Molinari2007}
\abx@aux@cite{Jefferson2005}
\abx@aux@cite{nsoesie2014}
\abx@aux@cite{quenel1998}
\abx@aux@cite{viboud2003}
\abx@aux@cite{degli2008}
\abx@aux@cite{carrasco2013}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{2}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2}Background}{2}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Influenza forecasting method}{2}}
\abx@aux@cite{leCun2015}
\abx@aux@cite{Miotto2017}
\abx@aux@cite{Pica2012}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Deep Learning and influenza}{4}}
\abx@aux@cite{chang2006influenza}
\abx@aux@cite{Lott1998}
\abx@aux@cite{flahault1998}
\abx@aux@cite{mcdonald2013}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3}Goal}{5}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4}Methodology}{5}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Data acquisition}{5}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces \textbf  {Predicting influenza activity.} The output (4) is generated by a recurrent neural network (RNN) taking, as input, the representation (3) extracted by a deep (2) convolution neural network (CNN) from (1) 3-D representation input obtained from preprocessing the different datasets, with the RNN trained to produce prediction based on the high-level representations of the data}}{6}}
\newlabel{fig:model}{{1}{6}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Convolutional Neural Networks}{7}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Reccurent Neural Networks}{8}}
\abx@aux@cite{abadi2016}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces  \textbf  {An unrolled recurrent neural network.} The artificial neurons (for example, hidden units grouped under node s with values $s_t$ at time t) get inputs from other neurons at previous time steps. In this way, a recurrent neural network can map an input sequence with elements $s_t$ into an output sequence with elements $o_t$, with each $o_t$ depending on all the previous $p'_t$ (for $t'\leq t$). The same parameters (matrices $U,V,W$ ) are used at each time step. }}{9}}
\newlabel{fig:RNN}{{2}{9}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Implementation, training and testing}{9}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {5}Time Plan}{10}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces  \textbf  {Timeline for the completion of the research.} The implementation of the Deep learning is divided in 4 phases : data acquisition, coding, training and evaluation of the models. The data acquisition and coding should be done by the end of February. The training and evaluation of the models should be done by the end of May.}}{11}}
\newlabel{fig:plan}{{3}{11}}
